name: gcp-build-and-deploy

on:
  push:
    branches: ["main"]
    paths:
      # App + container build inputs
      - "app/**"
      - "web/**"
      - "docker/**"
      - "cloudbuild.yaml"
      # Infra changes should redeploy too
      - "infra/gcp/cloud_run_demo/**"
      - "infra/gcp/modules/**"
      - ".github/workflows/gcp-build-and-deploy.yml"
  workflow_dispatch:
    inputs:
      env:
        description: "Environment (dev|stage|prod)"
        required: true
        default: "dev"

jobs:
  ci_backend:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install uv
        run: python -m pip install --upgrade pip uv

      - name: Install deps (uv)
        shell: bash
        run: |
          set -euo pipefail
          for attempt in 1 2 3; do
            if uv sync --dev; then
              exit 0
            fi
            if [ "${attempt}" -lt 3 ]; then
              echo "uv sync failed (attempt ${attempt}/3); retrying in 5s..."
              sleep 5
            fi
          done
          echo "uv sync failed after 3 attempts"
          exit 1

      - name: Lint (ruff)
        run: uv run ruff check .

      - name: Typecheck (mypy)
        run: uv run mypy app

      - name: "Smoke test: ingest + eval"
        run: |
          uv run python -m app.cli ingest-folder data/demo_corpus
          uv run python -m app.cli eval data/eval/golden.jsonl --k 5

  ci_frontend:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Enable pnpm
        run: corepack enable

      - name: Install + build
        working-directory: web
        run: |
          pnpm install --frozen-lockfile
          pnpm build

  terraform_hygiene:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      TF_DIR: infra/gcp/cloud_run_demo
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.14.4"

      - name: Terraform fmt (check)
        run: terraform -chdir=${TF_DIR} fmt -check -recursive

      - name: Terraform init (no backend)
        run: terraform -chdir=${TF_DIR} init -backend=false

      - name: Terraform validate
        run: terraform -chdir=${TF_DIR} validate

      - name: tflint (docker)
        run: |
          docker run --rm -v "${{ github.workspace }}:/repo" -w "/repo/${TF_DIR}" ghcr.io/terraform-linters/tflint:latest --init
          docker run --rm -v "${{ github.workspace }}:/repo" -w "/repo/${TF_DIR}" ghcr.io/terraform-linters/tflint:latest

      - name: tfsec (docker)
        run: docker run --rm -v "${{ github.workspace }}:/src" aquasec/tfsec:latest /src/${TF_DIR}

      - name: checkov (docker)
        run: |
          # NOTE: These skipped checks are org-policy dependent and are intentionally out of scope for
          # this public Cloud Run demo stack (cost + complexity tradeoffs).
          #
          # - CKV_GCP_84: Artifact Registry CMEK/CSEK enforcement (demo uses Google-managed encryption)
          # - CKV_GCP_26: VPC Flow Logs for every subnet (network module is optional; default is no VPC)
          # - CKV2_GCP_18: Require explicit firewall rules (network module is optional; default is no VPC)
          # - CKV_GCP_79: "latest major" is scanner-version sensitive; DB major upgrades are controlled explicitly
          # - CKV_GCP_6: check expects legacy require_ssl/trusted-cert mode; Terraform/provider baseline uses ssl_mode
          # - CKV_GCP_83: Pub/Sub CMEK/CSEK for optional demo ingest topics (Google-managed encryption baseline)
          # - CKV_SECRET_4: false-positive secret detection on DATABASE_URL format string template
          # - CKV_GCP_60: public IP is an intentional low-cost default; private IP remains available via cloudsql_private_ip_enabled=true
          docker run --rm -v "${{ github.workspace }}:/src" bridgecrew/checkov:latest \
            -d "/src/${TF_DIR}" \
            --skip-check "CKV_GCP_84,CKV_GCP_26,CKV2_GCP_18,CKV_GCP_79,CKV_GCP_6,CKV_GCP_83,CKV_SECRET_4,CKV_GCP_60"

      - name: conftest policy (docker)
        run: |
          set -euo pipefail
          # Pass explicit *.tf files so we don't accidentally parse .terraform/** artifacts.
          docker run --rm -v "${{ github.workspace }}:/project" -w /project openpolicyagent/conftest:latest test \
            --parser hcl2 \
            --policy infra/gcp/policy \
            $(find "${TF_DIR}" -path "${TF_DIR}/.terraform" -prune -o -type f -name "*.tf" -print)

  build_deploy:
    needs:
      - ci_backend
      - ci_frontend
      - terraform_hygiene
    runs-on: ubuntu-latest
    environment: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.env || 'dev' }}
    concurrency:
      group: gcp-build-and-deploy-${{ github.event_name == 'workflow_dispatch' && github.event.inputs.env || 'dev' }}
      cancel-in-progress: true
    permissions:
      contents: read
      id-token: write

    env:
      TF_DIR: infra/gcp/cloud_run_demo
      TF_CONFIG_GCS_PATH: ${{ vars.GCP_TF_CONFIG_GCS_PATH }}
      GCP_WIF_PROVIDER: ${{ vars.GCP_WIF_PROVIDER }}
      GCP_WIF_SERVICE_ACCOUNT: ${{ vars.GCP_WIF_SERVICE_ACCOUNT }}

    steps:
      - name: Assert required GitHub Environment variables
        shell: bash
        run: |
          set -euo pipefail
          : "These must be set at: Repo → Settings → Environments → <env> → Variables"
          test -n "${GCP_WIF_PROVIDER}" || { echo "::error::Missing env var: GCP_WIF_PROVIDER"; exit 1; }
          test -n "${GCP_WIF_SERVICE_ACCOUNT}" || { echo "::error::Missing env var: GCP_WIF_SERVICE_ACCOUNT"; exit 1; }
          test -n "${TF_CONFIG_GCS_PATH}" || { echo "::error::Missing env var: GCP_TF_CONFIG_GCS_PATH"; exit 1; }

          echo "WIF provider is set (length: ${#GCP_WIF_PROVIDER})"
          echo "WIF service account: ${GCP_WIF_SERVICE_ACCOUNT}"
          echo "Terraform config path: ${TF_CONFIG_GCS_PATH}"

      - name: Checkout
        uses: actions/checkout@v4

      - name: Auth to Google Cloud (WIF)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.GCP_WIF_PROVIDER }}
          service_account: ${{ env.GCP_WIF_SERVICE_ACCOUNT }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2

      - name: Fetch Terraform config from GCS
        shell: bash
        run: |
          set -euo pipefail
          echo "Fetching Terraform config from: ${TF_CONFIG_GCS_PATH}"
          gcloud storage cp "${TF_CONFIG_GCS_PATH}/backend.hcl" "${TF_DIR}/backend.hcl"
          gcloud storage cp "${TF_CONFIG_GCS_PATH}/terraform.tfvars" "${TF_DIR}/terraform.tfvars"

      - name: Parse terraform.tfvars (project/region/repo/service)
        id: cfg
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import os
          import pathlib
          import re

          tf_dir = pathlib.Path(os.environ["TF_DIR"])
          path = tf_dir / "terraform.tfvars"
          txt = path.read_text(encoding="utf-8")

          def get_str(key: str, default: str | None = None) -> str:
              # Supports:
              #   key = "value"
              #   key = value
              # Ignores commented lines and trailing comments.
              m = re.search(rf'^\s*{re.escape(key)}\s*=\s*"([^"]*)"\s*(?:#.*)?$', txt, re.M)
              if m:
                  return m.group(1)
              m = re.search(rf'^\s*{re.escape(key)}\s*=\s*([^\s#]+)\s*(?:#.*)?$', txt, re.M)
              if m:
                  return m.group(1)
              if default is not None:
                  return default
              raise SystemExit(f"Missing required key '{key}' in {path}")

          project_id = get_str("project_id")
          region = get_str("region")
          artifact_repo_name = get_str("artifact_repo_name")
          service_name = get_str("service_name")
          image_name = get_str("image_name", default="gkp")

          out_path = pathlib.Path(os.environ["GITHUB_OUTPUT"])
          out_path.write_text(
              "\n".join(
                  [
                      f"project_id={project_id}",
                      f"region={region}",
                      f"artifact_repo_name={artifact_repo_name}",
                      f"service_name={service_name}",
                      f"image_name={image_name}",
                      "",
                  ]
              ),
              encoding="utf-8",
          )
          PY

      - name: Set gcloud defaults (project + region)
        shell: bash
        run: |
          set -euo pipefail
          gcloud config set project "${{ steps.cfg.outputs.project_id }}"
          gcloud config set run/region "${{ steps.cfg.outputs.region }}"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.14.4"

      - name: Terraform init (remote state)
        shell: bash
        run: |
          set -euo pipefail
          terraform -chdir="${TF_DIR}" init -reconfigure \
            -backend-config="backend.hcl"

      - name: Bootstrap infra needed for image push (APIs + AR + runtime SA)
        shell: bash
        run: |
          set -euo pipefail
          terraform -chdir="${TF_DIR}" apply -auto-approve \
            -target=module.core_services \
            -target=module.artifact_registry \
            -target=module.service_accounts \
            -target=google_artifact_registry_repository_iam_member.cloud_build_writer

      - name: Compute image tag (immutable)
        id: image
        shell: bash
        run: |
          set -euo pipefail
          echo "image_tag=sha-${GITHUB_SHA}" >> "${GITHUB_OUTPUT}"

      - name: Build + push image (Cloud Build)
        shell: bash
        run: |
          set -euo pipefail

          ARTIFACT_REPO="${{ steps.cfg.outputs.region }}-docker.pkg.dev/${{ steps.cfg.outputs.project_id }}/${{ steps.cfg.outputs.artifact_repo_name }}"
          IMAGE="${ARTIFACT_REPO}/${{ steps.cfg.outputs.image_name }}:${{ steps.image.outputs.image_tag }}"

          echo "Pushing image: ${IMAGE}"

          # cloudbuild.yaml uses a single substitution:
          #   _IMAGE = full image URI (including tag)
          gcloud builds submit \
            --config cloudbuild.yaml \
            --substitutions "_IMAGE=${IMAGE}" \
            .

      - name: Update terraform.tfvars in GCS (image_tag)
        shell: bash
        run: |
          set -euo pipefail

          TFVARS="${TF_DIR}/terraform.tfvars"
          NEW_TAG="${{ steps.image.outputs.image_tag }}"

          python - <<'PY'
          import os
          import pathlib
          import re

          path = pathlib.Path(os.environ["TFVARS"])
          new_tag = os.environ["NEW_TAG"]
          txt = path.read_text(encoding="utf-8")

          # Replace an existing image_tag line, else append one.
          pat = re.compile(r'^(?P<indent>\s*)image_tag\s*=.*$', re.M)
          if pat.search(txt):
              txt = pat.sub(lambda m: f'{m.group("indent")}image_tag = "{new_tag}"', txt)
          else:
              if not txt.endswith("\n"):
                  txt += "\n"
              txt += f'image_tag = "{new_tag}"\n'

          path.write_text(txt, encoding="utf-8")
          PY

          echo "Uploading updated terraform.tfvars to: ${TF_CONFIG_GCS_PATH}/terraform.tfvars"
          gcloud storage cp "${TFVARS}" "${TF_CONFIG_GCS_PATH}/terraform.tfvars"
        env:
          TFVARS: ${{ env.TF_DIR }}/terraform.tfvars
          NEW_TAG: ${{ steps.image.outputs.image_tag }}

      - name: Log bucket lifecycle guard (best-effort)
        shell: bash
        run: |
          set -euo pipefail

          PROJECT_ID="${{ steps.cfg.outputs.project_id }}"
          BUCKET_ID="${{ steps.cfg.outputs.service_name }}-logs"

          # If the bucket is in DELETE_REQUESTED (soft-delete), Terraform can't modify it yet.
          STATE="$(gcloud logging buckets describe "${BUCKET_ID}" --project "${PROJECT_ID}" --location global --format='value(lifecycleState)' 2>/dev/null || echo NOT_FOUND)"
          echo "log_bucket=${BUCKET_ID}"
          echo "lifecycleState=${STATE}"

          if [ "${STATE}" = "DELETE_REQUESTED" ]; then
            echo "Undeleting ${BUCKET_ID} so Terraform can proceed..."
            gcloud logging buckets undelete "${BUCKET_ID}" --project "${PROJECT_ID}" --location global

            until [ "$(gcloud logging buckets describe "${BUCKET_ID}" --project "${PROJECT_ID}" --location global --format='value(lifecycleState)' 2>/dev/null || echo NOT_FOUND)" = "ACTIVE" ]; do
              echo "waiting for ${BUCKET_ID} to become ACTIVE..."
              sleep 15
            done
          fi

      - name: Terraform apply (deploy)
        shell: bash
        run: |
          set -euo pipefail
          terraform -chdir="${TF_DIR}" apply -auto-approve

      - name: Verify /health + /api/meta
        shell: bash
        run: |
          set -euo pipefail

          SERVICE_NAME="${{ steps.cfg.outputs.service_name }}"
          REGION="${{ steps.cfg.outputs.region }}"

          URL="$(gcloud run services describe "${SERVICE_NAME}" --region "${REGION}" --format='value(status.url)')"
          echo "Service URL: ${URL}"

          curl -fsS "${URL}/health" >/dev/null && echo "OK: /health"
          curl -fsS "${URL}/api/meta"
